{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step0a_Using_PySpark_to_clean_all_Null.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIZfgdzXciMg"
      },
      "source": [
        "# This file runs on ***Google Colab***\n",
        "## Before running this file, the Data Source file needs to be placed at the same level as this file\n",
        "\n",
        "### Data file name: hotel_reviews_for_PySpark_preprocessing.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CarnJEuzwP1B",
        "outputId": "a37667ae-ec9b-4554-c0a7-101833c103ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rIgn:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZilGKyDwUV_"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Cleaning_Data_for_PySpark\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOu9ay3cwZX9",
        "outputId": "e9c6f80c-e625-49db-cd01-13d2d4b1be59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Read in data \n",
        "from pyspark import SparkFiles\n",
        "file_path = \"hotel_reviews_for_PySpark_preprocessing.csv\"\n",
        "spark.sparkContext.addFile(file_path)\n",
        "df = spark.read.csv(SparkFiles.get(\"hotel_reviews_for_PySpark_preprocessing.csv\"), sep=\",\", header=True)\n",
        "\n",
        "# Show DataFrame\n",
        "df.show()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------+\n",
            "|              Review|Reviewer_Score|\n",
            "+--------------------+--------------+\n",
            "| I am so angry th...|           2.9|\n",
            "| No real complain...|           7.5|\n",
            "| Rooms are nice b...|           7.1|\n",
            "| My room was dirt...|           3.8|\n",
            "| You When I booke...|           6.7|\n",
            "| Backyard of the ...|           6.7|\n",
            "| Cleaner did not ...|           4.6|\n",
            "| Apart from the p...|          10.0|\n",
            "| Even though the ...|           6.5|\n",
            "| The aircondition...|           7.9|\n",
            "| Nothing all grea...|          10.0|\n",
            "| 6 30 AM started ...|           5.8|\n",
            "| The floor in my ...|           4.6|\n",
            "| This hotel is be...|           9.2|\n",
            "| The staff in the...|           8.8|\n",
            "| This hotel is aw...|          10.0|\n",
            "| Very steep steps...|           6.3|\n",
            "| We did not like ...|           7.5|\n",
            "| Public areas are...|           7.1|\n",
            "| We had issues wi...|           7.5|\n",
            "+--------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx5ryO5Bwe94"
      },
      "source": [
        "# checking for Null, nan, and '' \n",
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "# data_df.filter(data_df[\"Review\"] == \"\").count()\n",
        "# data_df.filter(data_df[\"Review\"].isNull()).count()\n",
        "# data_df.filter(isnan(data_df[\"Review\"])).count()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYmZ5Fr9I5sb",
        "outputId": "fa81e9b8-da6f-4cde-d914-4c17022e3971",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.filter(df[\"Review\"] == \"\").count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "max_XgwtI5zc",
        "outputId": "77973d2a-c4ab-466f-a767-81544873ed3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.filter(df[\"Review\"].isNull()).count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R5pIsDNI3nm",
        "outputId": "053c79a8-bb52-46a6-f801-33c387e8f87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.filter(isnan(df[\"Review\"])).count()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZi4FNbBJJ5M"
      },
      "source": [
        "df = df.where(col(\"Review\").isNotNull())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtjt_qLiJKAJ",
        "outputId": "ac5c387f-06a4-47b2-d8e7-a2e485d4cc48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df.filter(df[\"Review\"].isNull()).count()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn9OAhWSJKNt"
      },
      "source": [
        "df.toPandas().to_csv('data_ready_for_PySpark_NLP.csv', index=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Y6f72xxQ9p"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    }
  ]
}