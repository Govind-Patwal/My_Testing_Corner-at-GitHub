{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Step9_Final_NLP_reading_from_RDS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODYI86E6G0dU"
      },
      "source": [
        "# This file runs on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CarnJEuzwP1B",
        "outputId": "1e405025-1a8f-413d-c67c-7ae3f3490e38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Wa\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\r                                                                               \rHit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "\r0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\r                                                                               \rHit:7 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZilGKyDwUV_"
      },
      "source": [
        "# Start Spark session\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"Hotel_Reviews_NLP_from_RDS\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBrRnsEK1gI1",
        "outputId": "c784a31d-ebce-4968-a341-553353a208eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        }
      },
      "source": [
        "# Importing data from RDS (AWS)\n",
        "import psycopg2\n",
        "connection = psycopg2.connect(\n",
        "    host = 'sample-hotel-reviews.cfxm7dziqs2d.us-east-2.rds.amazonaws.com',\n",
        "    port = 5432,\n",
        "    user = 'postgres',\n",
        "    password = 'Postgres$123',\n",
        "    database = 'PySpark_NLP'\n",
        "    )\n",
        "cursor=connection.cursor()\n",
        "\n",
        "# using pandas to execute SQL queries\n",
        "import pandas as pd\n",
        "sql = \"\"\"\n",
        "SELECT *\n",
        "FROM public.\"Hotel_Review\"\n",
        "\"\"\"\n",
        "pandas_df = pd.read_sql(sql, con=connection)\n",
        "\n",
        "# Show DataFrame\n",
        "pandas_df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Reviewer_Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am so angry that i made this post available...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>No real complaints the hotel was great great ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You When I booked with your company on line y...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>Great location room was outstanding beds were...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>The cleaner knocked on our door at 8am which ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>This was my second time at this hotel the fir...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>Going as a family with two rooms hired in the...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>Some of the complimentary items of food from ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Review Reviewer_Sentiment\n",
              "0     I am so angry that i made this post available...           negative\n",
              "1     No real complaints the hotel was great great ...           positive\n",
              "2     Rooms are nice but for elderly a bit difficul...           positive\n",
              "3     My room was dirty and I was afraid to walk ba...           negative\n",
              "4     You When I booked with your company on line y...           positive\n",
              "..                                                 ...                ...\n",
              "995   Great location room was outstanding beds were...           positive\n",
              "996   The cleaner knocked on our door at 8am which ...           positive\n",
              "997   This was my second time at this hotel the fir...           positive\n",
              "998   Going as a family with two rooms hired in the...           positive\n",
              "999   Some of the complimentary items of food from ...           positive\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr9bgq0x3l1Y",
        "outputId": "2ba49071-89ab-4182-d7b7-d2878a551383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# converting PD dataframe to PySpark DataFrame\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Enable Arrow-based columnar data transfers\n",
        "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "\n",
        "# Create a Spark DataFrame from a pandas DataFrame using Arrow\n",
        "df = spark.createDataFrame(pandas_df)\n",
        "df.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/spark-3.0.1-bin-hadoop2.7/python/pyspark/sql/pandas/conversion.py:289: UserWarning: createDataFrame attempted Arrow optimization because 'spark.sql.execution.arrow.pyspark.enabled' is set to true; however, failed by the reason below:\n",
            "  PyArrow >= 0.15.1 must be installed; however, your version was 0.14.1.\n",
            "Attempting non-optimization as 'spark.sql.execution.arrow.pyspark.fallback.enabled' is set to true.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------------+\n",
            "|              Review|Reviewer_Sentiment|\n",
            "+--------------------+------------------+\n",
            "| I am so angry th...|          negative|\n",
            "| No real complain...|          positive|\n",
            "| Rooms are nice b...|          positive|\n",
            "| My room was dirt...|          negative|\n",
            "| You When I booke...|          positive|\n",
            "| Backyard of the ...|          positive|\n",
            "| Cleaner did not ...|          negative|\n",
            "| Apart from the p...|          positive|\n",
            "| Even though the ...|          positive|\n",
            "| The aircondition...|          positive|\n",
            "| Nothing all grea...|          positive|\n",
            "| 6 30 AM started ...|          positive|\n",
            "| The floor in my ...|          negative|\n",
            "| This hotel is be...|          positive|\n",
            "| Standard room is...|          positive|\n",
            "| The staff in the...|          positive|\n",
            "| This hotel is aw...|          positive|\n",
            "| Very steep steps...|          positive|\n",
            "| We did not like ...|          positive|\n",
            "| Public areas are...|          positive|\n",
            "+--------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sx5ryO5Bwe94"
      },
      "source": [
        "# Import functions\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF, StringIndexer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pf42Ru-woQ0",
        "outputId": "feaa5237-37be-446f-e013-920c08a4cd5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pyspark.sql.functions import length\n",
        "# Create a length column to be used as a future feature\n",
        "data_df = df.withColumn('length', length(df['Review']))\n",
        "data_df.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------------+------+\n",
            "|              Review|Reviewer_Sentiment|length|\n",
            "+--------------------+------------------+------+\n",
            "| I am so angry th...|          negative|  1913|\n",
            "| No real complain...|          positive|   611|\n",
            "| Rooms are nice b...|          positive|   301|\n",
            "| My room was dirt...|          negative|  1221|\n",
            "| You When I booke...|          positive|   774|\n",
            "| Backyard of the ...|          positive|   186|\n",
            "| Cleaner did not ...|          negative|   235|\n",
            "| Apart from the p...|          positive|   157|\n",
            "| Even though the ...|          positive|   162|\n",
            "| The aircondition...|          positive|   312|\n",
            "| Nothing all grea...|          positive|   568|\n",
            "| 6 30 AM started ...|          positive|   430|\n",
            "| The floor in my ...|          negative|   152|\n",
            "| This hotel is be...|          positive|   329|\n",
            "| Standard room is...|          positive|   134|\n",
            "| The staff in the...|          positive|   229|\n",
            "| This hotel is aw...|          positive|   413|\n",
            "| Very steep steps...|          positive|   270|\n",
            "| We did not like ...|          positive|   623|\n",
            "| Public areas are...|          positive|   166|\n",
            "+--------------------+------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnjC7sdrwyL0"
      },
      "source": [
        "# Create all the features to the data set\n",
        "convert_review_output_to_numbers = StringIndexer(inputCol='Reviewer_Sentiment',outputCol='label')\n",
        "tokenizer = Tokenizer(inputCol=\"Review\", outputCol=\"token_text\")\n",
        "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
        "hashingTF = HashingTF(inputCol=\"stop_tokens\", outputCol='hash_token')\n",
        "idf = IDF(inputCol='hash_token', outputCol='idf_token')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StQhEWRw254y"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.linalg import Vector\n",
        "# Create feature vectors\n",
        "clean_up = VectorAssembler(inputCols=['idf_token', 'length'], outputCol='features')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pwTN86YzVPj"
      },
      "source": [
        "# Create and run a data processing Pipeline\n",
        "from pyspark.ml import Pipeline\n",
        "data_prep_pipeline = Pipeline(stages=[convert_review_output_to_numbers, tokenizer, stopremove, hashingTF, idf, clean_up])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as1ctTNS0Nff",
        "outputId": "da54d250-1199-48a2-96e0-34b6521ad0ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Fit and transform the pipeline\n",
        "cleaner = data_prep_pipeline.fit(data_df)\n",
        "cleaned = cleaner.transform(data_df)\n",
        "\n",
        "# Show \"Combined_Review\" and resulting features\n",
        "cleaned.select(['label', 'features']).show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+--------------------+\n",
            "|label|            features|\n",
            "+-----+--------------------+\n",
            "|  1.0|(262145,[2437,302...|\n",
            "|  0.0|(262145,[4714,514...|\n",
            "|  0.0|(262145,[22346,23...|\n",
            "|  1.0|(262145,[1797,230...|\n",
            "|  0.0|(262145,[14870,20...|\n",
            "|  0.0|(262145,[9781,304...|\n",
            "|  1.0|(262145,[21641,34...|\n",
            "|  0.0|(262145,[25789,43...|\n",
            "|  0.0|(262145,[22815,31...|\n",
            "|  0.0|(262145,[2437,216...|\n",
            "|  0.0|(262145,[9129,181...|\n",
            "|  0.0|(262145,[1696,383...|\n",
            "|  1.0|(262145,[1729,216...|\n",
            "|  0.0|(262145,[15370,23...|\n",
            "|  0.0|(262145,[4319,861...|\n",
            "|  0.0|(262145,[6957,304...|\n",
            "|  0.0|(262145,[5765,218...|\n",
            "|  0.0|(262145,[3280,110...|\n",
            "|  0.0|(262145,[329,9129...|\n",
            "|  0.0|(262145,[11941,17...|\n",
            "+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Qe1rrGv0Nkn"
      },
      "source": [
        "# Break data down into a training set and a testing set\n",
        "training, testing = cleaned.randomSplit([0.7, 0.3], 21)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtPLIwaa0Nnf"
      },
      "source": [
        "from pyspark.ml.classification import NaiveBayes\n",
        "# Create a Naive Bayes model and fit training data\n",
        "nb = NaiveBayes()\n",
        "predictor = nb.fit(training)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHb4DHem0Np9",
        "outputId": "19941b48-98a3-4577-f8ae-d302e8dc3e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Transform the data with the testing data\n",
        "test_results = predictor.transform(testing)\n",
        "test_results.show(10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|              Review|Reviewer_Sentiment|length|label|          token_text|         stop_tokens|          hash_token|           idf_token|            features|       rawPrediction|         probability|prediction|\n",
            "+--------------------+------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "| A little far fro...|          positive|   123|  0.0|[, a, little, far...|[, little, far, c...|(262144,[11995,21...|(262144,[11995,21...|(262145,[11995,21...|[-431.96374968016...|[1.0,3.7705361372...|       0.0|\n",
            "| Architecturally ...|          positive|   602|  0.0|[, architecturall...|[, architecturall...|(262144,[7485,866...|(262144,[7485,866...|(262145,[7485,866...|[-3420.4476796049...|           [1.0,0.0]|       0.0|\n",
            "| Beautiful gothic...|          positive|   235|  0.0|[, beautiful, got...|[, beautiful, got...|(262144,[6501,912...|(262144,[6501,912...|(262145,[6501,912...|[-1168.1830614297...|[1.0,3.0368581224...|       0.0|\n",
            "| Being given a ri...|          positive|   527|  0.0|[, being, given, ...|[, given, ridicul...|(262144,[3837,126...|(262144,[3837,126...|(262145,[3837,126...|[-2618.4632986772...|           [1.0,0.0]|       0.0|\n",
            "| Breakfast was ex...|          positive|   242|  0.0|[, breakfast, was...|[, breakfast, exp...|(262144,[6498,100...|(262144,[6498,100...|(262145,[6498,100...|[-1017.1917627590...|[1.0,7.0929116891...|       0.0|\n",
            "| Breakfast was ve...|          positive|   177|  0.0|[, breakfast, was...|[, breakfast, nic...|(262144,[21641,22...|(262144,[21641,22...|(262145,[21641,22...|[-626.00446716483...|[1.0,2.8092689892...|       0.0|\n",
            "| Building work go...|          positive|   160|  0.0|[, building, work...|[, building, work...|(262144,[34343,69...|(262144,[34343,69...|(262145,[34343,69...|[-761.51898129477...|[1.0,4.4153416759...|       0.0|\n",
            "| Building work is...|          positive|   162|  0.0|[, building, work...|[, building, work...|(262144,[34343,87...|(262144,[34343,87...|(262145,[34343,87...|[-706.77411801349...|[1.0,1.1351421661...|       0.0|\n",
            "| Cold and smelly ...|          positive|    44|  0.0|[, cold, and, sme...|[, cold, smelly, ...|(262144,[24016,41...|(262144,[24016,41...|(262145,[24016,41...|[-221.05194736718...|[1.0,9.1668553857...|       0.0|\n",
            "| Construction on ...|          positive|   394|  0.0|[, construction, ...|[, construction, ...|(262144,[19352,21...|(262144,[19352,21...|(262145,[19352,21...|[-1707.5168532549...|           [1.0,0.0]|       0.0|\n",
            "+--------------------+------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shc-i0sR0NxL",
        "outputId": "b194f6d2-ad5e-41c2-90fa-1329130bbcc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Use the Class Evaluator for a cleaner description\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "acc_eval = MulticlassClassificationEvaluator()\n",
        "acc = acc_eval.evaluate(test_results)\n",
        "print(\"Accuracy of model at predicting reviews was: %f\" %acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of model at predicting reviews was: 0.917460\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9Y6f72xxQ9p"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}